{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22a8efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\roeel\\projects\\sela\\data-engineering-copilot-workshop\\venv\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\roeel\\projects\\sela\\data-engineering-copilot-workshop\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\roeel\\projects\\sela\\data-engineering-copilot-workshop\\venv\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Spark session initialized successfully!\n",
      "Spark version: 3.4.1\n",
      "Running on: win32\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "%pip install pyspark python-dotenv\n",
    "\n",
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection string\n",
    "DB_CONNECTION = os.getenv('DB_CONNECTION_STRING', \n",
    "                          'postgresql://postgressadmin:wf**F!$3dGdf14@copilot-workshop-db.postgres.database.azure.com:5432/workshop_db')\n",
    "\n",
    "# IMPORTANT: Set up Hadoop for Windows BEFORE creating Spark session\n",
    "if sys.platform.startswith('win'):\n",
    "    # Create a minimal Hadoop directory structure for Windows\n",
    "    hadoop_home = os.path.join(os.path.expanduser('~'), '.hadoop')\n",
    "    os.makedirs(hadoop_home, exist_ok=True)\n",
    "    os.makedirs(os.path.join(hadoop_home, 'bin'), exist_ok=True)\n",
    "    os.environ['HADOOP_HOME'] = hadoop_home\n",
    "    \n",
    "    # Download winutils.exe if not present (required for Windows)\n",
    "    winutils_path = os.path.join(hadoop_home, 'bin', 'winutils.exe')\n",
    "    if not os.path.exists(winutils_path):\n",
    "        print(\"‚ö†Ô∏è winutils.exe not found. Downloading...\")\n",
    "        import urllib.request\n",
    "        try:\n",
    "            urllib.request.urlretrieve(\n",
    "                'https://github.com/steveloughran/winutils/raw/master/hadoop-3.0.0/bin/winutils.exe',\n",
    "                winutils_path\n",
    "            )\n",
    "            print(\"‚úÖ winutils.exe downloaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not download winutils.exe automatically: {e}\")\n",
    "            print(\"Please download manually from: https://github.com/steveloughran/winutils\")\n",
    "\n",
    "# Initialize Spark Session with PostgreSQL driver\n",
    "# Note: The driver will be downloaded on first run, which may take a moment\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataPipelineDebugging\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.3\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark session initialized successfully!\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Running on: {sys.platform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c5d23",
   "metadata": {},
   "source": [
    "# üêõ Data Pipeline Debugging Exercise\n",
    "\n",
    "This notebook contains a data pipeline with **several bugs and performance issues**. Your task is to use GitHub Copilot to identify and fix them.\n",
    "\n",
    "## Your Mission:\n",
    "Use GitHub Copilot Chat to:\n",
    "1. Review the code and identify issues\n",
    "2. Understand what each section is trying to accomplish\n",
    "3. Fix bugs and optimize performance\n",
    "4. Add proper error handling and validation\n",
    "\n",
    "## Hints:\n",
    "- Try asking Copilot to review specific cells\n",
    "- Ask about performance optimization\n",
    "- Request explanations for suspicious code patterns\n",
    "- Use Copilot to suggest best practices\n",
    "\n",
    "Good luck! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c343c",
   "metadata": {},
   "source": [
    "## Step 1: Load Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0bb102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 customers\n",
      "Loaded 5000 orders\n",
      "Loaded 14945 order items\n",
      "Loaded 200 products\n"
     ]
    }
   ],
   "source": [
    "# Load data from PostgreSQL database\n",
    "# Parse connection string properly for JDBC\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed = urlparse(DB_CONNECTION)\n",
    "jdbc_url = f\"jdbc:postgresql://{parsed.hostname}:{parsed.port}{parsed.path}?ssl=true&sslmode=require\"\n",
    "username = parsed.username\n",
    "password = parsed.password\n",
    "\n",
    "# Load with proper authentication\n",
    "customers = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", \"raw.customers\") \\\n",
    "    .option(\"user\", username) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "orders = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", \"raw.orders\") \\\n",
    "    .option(\"user\", username) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "order_items = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", \"raw.order_items\") \\\n",
    "    .option(\"user\", username) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "products = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", \"raw.products\") \\\n",
    "    .option(\"user\", username) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "print(f\"Loaded {customers.count()} customers\")\n",
    "print(f\"Loaded {orders.count()} orders\")\n",
    "print(f\"Loaded {order_items.count()} order items\")\n",
    "print(f\"Loaded {products.count()} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfbe40",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Product Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a056749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Products by Revenue:\n",
      "+----------+--------------------+--------+---------------+--------------+----------+\n",
      "|product_id|        product_name|category|  total_revenue|total_quantity|num_orders|\n",
      "+----------+--------------------+--------+---------------+--------------+----------+\n",
      "|       143|Advanced systemic...|Clothing|154588.77000000|           171|        89|\n",
      "|        97|Enhanced systemat...|    Home|152286.59100000|           183|        91|\n",
      "|        12|Operative needs-b...|    Home|150842.72300000|           163|        80|\n",
      "|        57|Versatile hybrid ...|    Home|147685.98000000|           162|        74|\n",
      "|       200|Quality-focused s...|    Home|147551.52600000|           175|        87|\n",
      "|       126|Visionary zero-de...|  Sports|146205.80550000|           165|        83|\n",
      "|       129|Assimilated syste...|   Books|143324.25300000|           177|        83|\n",
      "|        75|Synergistic heuri...|    Home|142905.51450000|           173|        86|\n",
      "|       145|Public-key high-l...|  Sports|141368.47200000|           172|        83|\n",
      "|       138|Synergized zero t...|  Sports|138324.53150000|           153|        73|\n",
      "+----------+--------------------+--------+---------------+--------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join order items with product information\n",
    "product_sales = order_items.join(\n",
    "    products,\n",
    "    order_items.product_id == products.product_id,  # ‚úÖ FIXED: correct join key\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Calculate line total with discount applied\n",
    "product_sales = product_sales.withColumn(\n",
    "    \"line_total\",\n",
    "    F.col(\"quantity\") * F.col(\"unit_price\") * (1 - F.col(\"discount_percent\") / 100)  # ‚úÖ FIXED: discount is percentage\n",
    ")\n",
    "\n",
    "# Aggregate revenue by product\n",
    "revenue_by_product = product_sales.groupBy(\n",
    "    order_items.product_id,  # ‚úÖ FIXED: specify which product_id\n",
    "    \"product_name\", \n",
    "    \"category\"\n",
    ").agg(\n",
    "    F.sum(\"line_total\").alias(\"total_revenue\"),\n",
    "    F.sum(\"quantity\").alias(\"total_quantity\"),\n",
    "    F.count(\"order_item_id\").alias(\"num_orders\")\n",
    ")\n",
    "\n",
    "print(\"Top 10 Products by Revenue:\")\n",
    "revenue_by_product.orderBy(F.desc(\"total_revenue\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25befea5",
   "metadata": {},
   "source": [
    "## Step 3: Customer Segmentation (RFM Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde59f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Segmentation Results:\n",
      "+-----------+----------------+---------+-------+---------+--------+-------+-------+-------+---------+\n",
      "|customer_id|   customer_name|  country|recency|frequency|monetary|r_score|f_score|m_score|rfm_score|\n",
      "+-----------+----------------+---------+-------+---------+--------+-------+-------+-------+---------+\n",
      "|         28|     Lisa Harper|      USA|    248|        3| 6604.49|      5|      3|      4|       12|\n",
      "|        245|Gabriella Newman|Australia|   -656|       10|18746.24|      1|      5|      5|       11|\n",
      "|        822|  Amanda Nichols|    Japan|   -643|       10|26314.35|      1|      5|      5|       11|\n",
      "|        321|     Eric Harris|       UK|   -621|       10|26300.73|      1|      5|      5|       11|\n",
      "|        101|      Mark Brown|      USA|   -639|       10|28487.46|      1|      5|      5|       11|\n",
      "|        327|  Molly Phillips|   Canada|   -582|       11|28850.00|      1|      5|      5|       11|\n",
      "|        518|     Brian Ellis|   France|   -631|       11|19966.28|      1|      5|      5|       11|\n",
      "|        777|  Tyler Morse MD|       UK|   -653|       11|24735.26|      1|      5|      5|       11|\n",
      "|        711|  Emily Robinson|   Canada|   -624|       10|29456.69|      1|      5|      5|       11|\n",
      "|        395|  Joseph Simmons|      USA|   -647|       11|36315.08|      1|      5|      5|       11|\n",
      "+-----------+----------------+---------+-------+---------+--------+-------+-------+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Calculate RFM metrics for customer segmentation\n",
    "reference_date = datetime(2024, 1, 1)\n",
    "\n",
    "# Join customers with their orders\n",
    "customer_orders = customers.join(\n",
    "    orders,\n",
    "    customers.customer_id == orders.customer_id,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Calculate RFM metrics - FIX: Specify which customer_id to use\n",
    "rfm = customer_orders.groupBy(\n",
    "    customers.customer_id,  # ‚úÖ FIXED: Specify customers.customer_id\n",
    "    customers.customer_name,  # ‚úÖ FIXED: Specify customers.customer_name\n",
    "    customers.country  # ‚úÖ FIXED: Specify customers.country\n",
    ").agg(\n",
    "    F.datediff(F.lit(reference_date), F.max(\"order_date\")).alias(\"recency\"),\n",
    "    F.count(\"order_id\").alias(\"frequency\"),\n",
    "    F.sum(\"total_amount\").alias(\"monetary\")\n",
    ")\n",
    "\n",
    "\n",
    "# Score recency (1-5 scale)\n",
    "rfm = rfm.withColumn(\n",
    "    \"r_score\",\n",
    "    F.when(F.col(\"recency\") < 30, 1)\n",
    "     .when(F.col(\"recency\") < 60, 2)\n",
    "     .when(F.col(\"recency\") < 90, 3)\n",
    "     .when(F.col(\"recency\") < 180, 4)\n",
    "     .otherwise(5)\n",
    ").withColumn(\n",
    "    \"f_score\",\n",
    "    F.when(F.col(\"frequency\") >= 10, 5)\n",
    "     .when(F.col(\"frequency\") >= 5, 4)\n",
    "     .when(F.col(\"frequency\") >= 3, 3)\n",
    "     .when(F.col(\"frequency\") >= 2, 2)\n",
    "     .otherwise(1)\n",
    ").withColumn(\n",
    "    \"m_score\",\n",
    "    F.when(F.col(\"monetary\") >= 10000, 5)\n",
    "     .when(F.col(\"monetary\") >= 5000, 4)\n",
    "     .when(F.col(\"monetary\") >= 2000, 3)\n",
    "     .when(F.col(\"monetary\") >= 1000, 2)\n",
    "     .otherwise(1)\n",
    ")\n",
    "\n",
    "# Calculate overall RFM score\n",
    "rfm = rfm.withColumn(\n",
    "    \"rfm_score\",\n",
    "    F.col(\"r_score\") + F.col(\"f_score\") + F.col(\"m_score\")\n",
    ")\n",
    "\n",
    "print(\"Customer Segmentation Results:\")\n",
    "rfm.orderBy(F.desc(\"rfm_score\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4ba11",
   "metadata": {},
   "source": [
    "## Step 4: Sales Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe04b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Sales Trends:\n",
      "+-------+------------+----------------+---------+---------------+\n",
      "|  month|total_orders|unique_customers|  revenue|avg_order_value|\n",
      "+-------+------------+----------------+---------+---------------+\n",
      "|2022-10|           1|            3357|  4534.38|        4534.38|\n",
      "|2022-11|           7|           10695| 23073.93|       23073.93|\n",
      "|2022-12|          11|           27620| 23143.12|       23143.12|\n",
      "|2023-01|          19|           34890| 48228.43|       48228.43|\n",
      "|2023-02|          17|           38328| 45183.13|       45183.13|\n",
      "|2023-03|          21|           52780| 58394.79|       58394.79|\n",
      "|2023-04|          32|           92342| 88952.34|       88952.34|\n",
      "|2023-05|          28|           66708| 90367.89|       90367.89|\n",
      "|2023-06|          39|           91486|100800.34|      100800.34|\n",
      "|2023-07|          24|           65449| 62624.36|       62624.36|\n",
      "|2023-08|          45|          117198|123906.14|      123906.14|\n",
      "|2023-09|          50|          120312|144155.44|      144155.44|\n",
      "+-------+------------+----------------+---------+---------------+\n",
      "only showing top 12 rows\n",
      "\n",
      "\n",
      "Monthly Growth Rates:\n",
      "+-------+---------+------------------+-----------------+\n",
      "|  month|  revenue|prev_month_revenue|      growth_rate|\n",
      "+-------+---------+------------------+-----------------+\n",
      "|2022-10|  4534.38|          23073.93|-80.3484711967142|\n",
      "|2022-11| 23073.93|          23143.12| -0.2989657401422|\n",
      "|2022-12| 23143.12|          48228.43|-52.0135322671710|\n",
      "|2023-01| 48228.43|          45183.13|  6.7399049158392|\n",
      "|2023-02| 45183.13|          58394.79|-22.6247238837574|\n",
      "|2023-03| 58394.79|          88952.34|-34.3527219182767|\n",
      "|2023-04| 88952.34|          90367.89| -1.5664302884575|\n",
      "|2023-05| 90367.89|         100800.34|-10.3496178683524|\n",
      "|2023-06|100800.34|          62624.36| 60.9602716898025|\n",
      "|2023-07| 62624.36|         123906.14|-49.4582270095735|\n",
      "|2023-08|123906.14|         144155.44|-14.0468510935141|\n",
      "|2023-09|144155.44|         188787.95|-23.6416095412869|\n",
      "|2023-10|188787.95|         153222.64| 23.2115240933063|\n",
      "|2023-11|153222.64|         180539.87|-15.1308572449952|\n",
      "|2023-12|180539.87|         226895.19|-20.4302788437252|\n",
      "|2024-01|226895.19|         194740.55| 16.5115277737482|\n",
      "|2024-02|194740.55|         211666.84| -7.9966658924941|\n",
      "|2024-03|211666.84|         270632.81|-21.7881822976305|\n",
      "|2024-04|270632.81|         328508.35|-17.6176769935985|\n",
      "|2024-05|328508.35|         346504.10| -5.1935171907057|\n",
      "+-------+---------+------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate monthly sales trends\n",
    "monthly_sales = orders.withColumn(\n",
    "    \"month\",\n",
    "    F.date_format(\"order_date\", \"yyyy-MM\")\n",
    ")\n",
    "\n",
    "# Aggregate sales by month - ‚úÖ FIXED: Correct aggregations\n",
    "monthly_sales = monthly_sales.groupBy(\"month\") \\\n",
    "    .agg(\n",
    "        F.count(\"order_id\").alias(\"total_orders\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\"),  # ‚úÖ FIXED: Count distinct customers\n",
    "        F.sum(\"total_amount\").alias(\"revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\")  # ‚úÖ FIXED: Calculate average\n",
    "    )\n",
    "\n",
    "print(\"Monthly Sales Trends:\")\n",
    "monthly_sales.orderBy(\"month\").show(12)\n",
    "\n",
    "# Calculate month-over-month growth rate - ‚úÖ FIXED: Use lag() not lead()\n",
    "windowSpec = Window.orderBy(\"month\")\n",
    "monthly_sales = monthly_sales.withColumn(\n",
    "    \"prev_month_revenue\",\n",
    "    F.lag(\"revenue\").over(windowSpec)  # ‚úÖ FIXED: Use lag() for previous month\n",
    ")\n",
    "\n",
    "monthly_sales = monthly_sales.withColumn(\n",
    "    \"growth_rate\",\n",
    "    ((F.col(\"revenue\") - F.col(\"prev_month_revenue\")) / F.col(\"prev_month_revenue\") * 100)\n",
    ")\n",
    "\n",
    "print(\"\\nMonthly Growth Rates:\")\n",
    "monthly_sales.select(\"month\", \"revenue\", \"prev_month_revenue\", \"growth_rate\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
